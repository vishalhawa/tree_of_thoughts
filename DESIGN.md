---
editor_options: 
  markdown: 
    wrap: 72
---

# Design Document — Clean ToT Portfolio POC (LLM-first)

## 1) Purpose

This project implements a **Tree-of-Thoughts (ToT)** style search for
**portfolio construction strategies** under multiple objectives:

-   **maximize**: Sharpe ratio
-   **penalize / constrain**: CVaR(99%), Max Drawdown, and full turnover

The architecture is intentionally **generic**:

-   The **LLM proposes** candidate “branches” (strategy specifications)
    within a strict grammar.
-   A deterministic **evaluation engine** computes objective metrics via
    rolling, walk-forward backtests.
-   A deterministic **selection engine** prunes and promotes candidates
    using Pareto dominance, quotas, and evaluation budgets.

This separation keeps the search interpretable and safe: **the LLM never
“decides winners”**; it only proposes candidates to be evaluated.

------------------------------------------------------------------------

## 2) High-level Flow

```         
R_xts (daily returns xts)
   |
   v
Seed nodes (one or more per method family)  [R/methods.R]
   |
   v
FAST eval (limited OOS months)              [R/tot_pipeline.R -> evaluate_nodes()]
   |
   v
Prune (Pareto + quota per method)           [R/selection.R -> prune_by_method_quota()]
   |
   v
MEDIUM eval (more OOS months)               [R/tot_pipeline.R -> evaluate_nodes()]
   |
   v
Prune again (Pareto + quota)                [R/selection.R]
   |
   v
For k = 1..n_rounds (LLM rounds):
   - LLM proposes seeds + edits              [R/llm_planner.R]
   - sanitize/validate + fallback seeds      [R/llm_planner.R]
   - FAST eval -> prune -> MEDIUM eval       [R/tot_pipeline.R]
   - frontier := medium_keep
   |
   v
DEEP eval on final frontier + prune          [R/tot_pipeline.R]
   |
   v
Rank (optional scalar score for “one pick”)  [R/tot_pipeline.R -> rank_final()]
```

**Key idea:** use small/cheap evaluations early (FAST), then spend
compute only on promising candidates (MEDIUM/DEEP).

------------------------------------------------------------------------

## 3) Core Data Model

The pipeline moves around a **node table** (a tibble). Each row is one
candidate strategy specification + its evaluation.

### Node fields (most important)

-   `node_id`: unique id (generated by `new_id()` in `R/utils.R`)
-   `parent_id`: lineage pointer (for “edits”; optional)
-   `depth`: search depth (0 = seeds)
-   `method_family`: the strategy “construction method” (diversity axis)
-   `W`: rolling lookback window (days) used by the strategy
    (hyperparameter)
-   `params`: method-specific parameters (list-column)
-   `constraints`: constraints (list-column), currently `max_w` (max
    position weight)
-   `eval_level`: `"fast" | "medium" | "deep"`
-   `feasible`: TRUE/FALSE (invalid weights or objective issues are
    infeasible)
-   objectives:
    -   `sharpe`
    -   `cvar99`
    -   `maxdd`
    -   `turnover_full`
-   `diagnostics`: list-column for extra debug info
-   `rationale`: explanation string (LLM or fallback)

### What is a “branch” in this ToT?

A branch is a **complete spec** describing how weights are produced over
time: `(method_family, W, params, constraints)`.

Everything else (objectives, feasibility) is derived by evaluation.

------------------------------------------------------------------------

## 4) Evaluation Engine

### Where it lives

-   **Metrics**: `R/metrics.R`
-   **Walk-forward evaluation**: `R/evaluator.R`
    (`evaluate_strategy_walkforward()`)

### How evaluation works (monthly rebalancing)

Given daily returns `R_xts`:

1.  Create monthly endpoints (`endpoints(..., on="months")`).
2.  For each rebalance month:
    -   Training window: last `W` trading days
    -   Weight generation: call `weight_fn(R_window)`
    -   Enforce constraints:
        -   long-only, sum(weights)=1
        -   max weight \<= `constraints$max_w` (default 0.7)
3.  Apply weights over the next month to get daily portfolio returns.
4.  Collect out-of-sample (OOS) daily returns and the rebalanced weights
    sequence.

### Evaluation budgets (FAST / MEDIUM / DEEP)

Defined in `R/tot_pipeline.R`:

-   `fast`: 24 OOS months
-   `medium`: 60 OOS months
-   `deep`: all available (`Inf`)

This is controlled by: - `oos_months_for_level(eval_level)` in
`R/tot_pipeline.R` - passed into
`evaluate_strategy_walkforward(..., oos_months_limit=...)`

### Objective computations

From OOS daily portfolio returns:

-   Sharpe: `calc_sharpe()`
-   CVaR(99%): `calc_cvar_hist(alpha=0.99)` using empirical tail mean
-   MaxDD: `calc_maxdd()`
-   Turnover: `calc_turnover_full(weights_mat)` based on full rebalances

**Feasibility rules:** if any required objective is non-finite
(`NA/NaN/Inf`) the node is marked infeasible, so selection never crashes
and metrics remain trustworthy.

------------------------------------------------------------------------

## 5) Method Families (Construction Methods)

### Where it lives

-   `R/methods.R`

Method families are the **diversity axis**. Each family defines:

-   `sampler()`: generates a random parameter set (seed proposals)
-   `editor(params)`: mutates parameters for children (micro-edits)
-   `weight_fn_factory(params, constraints)`: returns a function
    `weight_fn(R_window, spec)` that produces a weight vector

### Default method families

Defined by `default_method_families()`:

-   `min_var_pa` — PortfolioAnalytics minimum variance
-   `etl99_pa` — PortfolioAnalytics CVaR/ETL optimizer (99%)
-   `quad_utility_pa` — PortfolioAnalytics quadratic utility
-   `risk_parity` — proxy inverse-vol risk parity
-   `trend_overlay` — proxy trend-based overlay on baseline weights

### Risk parity hyperparameter (`vol_lb`)

The risk parity proxy uses:

-   `W`: rolling window for the ToT spec (used to select training slice)
-   `vol_lb`: volatility estimation lookback (snapped to a grid)

`vol_lb` is validated/sanitized in `R/llm_planner.R`
(`sanitize_params()`), and used in the proxy weight function in
`R/methods.R`.

------------------------------------------------------------------------

## 6) Selection Engine (Pruning + Promotion)

### Where it lives

-   `R/selection.R`
-   `R/utils.R` (spec dedup)

Selection has two jobs:

1.  **Remove duplicates** (same spec) to avoid wasted compute
2.  **Keep a small frontier** that balances:
    -   exploitation (good objective values)
    -   exploration (keep at least some candidates per method family)

### 6.1 Spec-level Dedup

`dedup_by_spec()` in `R/utils.R` computes a signature over:

-   `method_family`
-   `W`
-   `params`
-   `constraints$max_w`

and drops duplicates **ignoring** `node_id`, `parent_id`, and
`rationale`.

This solves practical issues like: - LLM proposing the same candidate
twice with different rationales - fallback seeds colliding with LLM
seeds

### 6.2 Pareto dominance

A candidate A dominates B if it is no worse in all loss dimensions and
strictly better in at least one, allowing slack `eps`.

Loss vector is built from objectives:

-   `sharpe_loss = -sharpe`
-   `cvar_loss   = -cvar99` (because less negative is better)
-   `dd_loss     = -maxdd`
-   `turnover    = turnover_full`

Functions: - `dominates()` - `pareto_nondominated_idx()`

### 6.3 Exploration quota (per method family)

`prune_by_method_quota(nodes_tbl, K_per_method, eps)`:

-   Computes the Pareto non-dominated set within each `method_family`
-   Keeps up to `K_per_method` from that set
-   **If fewer than `K_per_method` are Pareto**, it fills with best
    dominated candidates

This prevents early collapse where one method family dominates and
others disappear.

### 6.4 Successive halving (FAST → MEDIUM → DEEP)

The pipeline first evaluates candidates in **FAST**, prunes, then
re-evaluates survivors in **MEDIUM**, prunes again, and finally does
**DEEP** evaluation on the final frontier.

The compute-saving “decision point” is: **only survivors get promoted to
more expensive evaluation levels**.

------------------------------------------------------------------------

## 7) LLM Planner (Proposal Generator)

### Where it lives

-   `R/llm_planner.R`

LLM usage is optional and controlled by `use_llm`.

### Inputs to the LLM

We pass a compact table of current survivors:

-   id, method_family, W
-   objective metrics (sharpe/cvar99/maxdd/turnover)
-   a derived `weakness` tag (`risk | sharpe | turnover | balanced`)

### Output contract

LLM must return **JSON only**:

``` json
{
  "seeds": [
    {"method_family": "...", "W": 180, "params": {...}, "rationale": "..."}
  ],
  "edits": [
    {"parent_id": "n00001", "method_family": "...", "W": 195, "params": {...}, "rationale": "..."}
  ]
}
```

### Validation & safety

Before anything reaches evaluation:

1.  `extract_json()` parses the response (including best-effort
    extraction).
2.  `sanitize_params()` clamps values and drops unknown keys.
3.  `snap_W()` enforces W grid.
4.  Invalid method families or parents are dropped.
5.  `fallback_seeds()` ensures a minimum exploration budget per method
    even if LLM fails.

**Important:** the LLM does not get raw data or code execution. It only
sees summary metrics and the allowed grammar.

------------------------------------------------------------------------

## 8) The Main Orchestrator: `run_tot()`

### Where it lives

-   `R/tot_pipeline.R`

`run_tot()` is the primary API. It wires together:

-   registry creation (`make_method_registry()`)
-   initial seeding (`seed_nodes()`)
-   evaluation (`evaluate_nodes()`)
-   selection (`prune_by_method_quota()`)
-   LLM rounds (`run_llm_round()`)
-   final deep evaluation + ranking

### Output of `run_tot()`

A list:

-   `rounds`: each LLM round’s proposals + fast/medium keeps
-   `final_medium`: final frontier after LLM rounds (medium eval level)
-   `final_deep`: deep-evaluated frontier
-   `ranked`: final_deep plus scalar score ranking

------------------------------------------------------------------------

## 9) Configuration Guide (What to Change and Where)

Most users only need to tune the arguments to `run_tot()`.

### 9.1 Core knobs (run_tot arguments)

| Knob | Default | Where | What it changes |
|-----------------|--------------------:|-----------------|-----------------|
| `use_llm` | TRUE | `run_tot()` | enables/disables LLM proposals |
| `n_rounds` | 3 | `run_tot()` | number of LLM propose/eval cycles |
| `init_seeds_per_method` | 2 | `run_tot()` | initial random seeds per method family |
| `seeds_per_method` | 1 | `run_tot()` | LLM seed proposals per method family per round |
| `edits_per_parent` | 2 | `run_tot()` | LLM edits per survivor per round |
| `K_per_method` | 2 | `run_tot()` | frontier size per method family (quota) |
| `eps` | c(0,0,0,0) | `run_tot()` | Pareto dominance slack |
| `alpha_cvar` | 0.99 | `run_tot()` | CVaR confidence level |
| `constraints$max_w` | 0.7 | `run_tot()` | max position weight |

### 9.2 Evaluation budgets

Change `oos_months_for_level()` in `R/tot_pipeline.R`:

-   increase/decrease FAST and MEDIUM months to trade off speed vs
    stability
-   DEEP is `Inf` by default

### 9.3 W range & step

Change `snap_W()` in `R/utils.R` and the prompt grammar in
`R/llm_planner.R`.

### 9.4 Ranking weights (optional)

`rank_final()` in `R/tot_pipeline.R` defines an optional scalar score.

Adjust weights: - `lam_dd` (maxdd penalty) - `lam_cvar` (cvar penalty) -
`lam_to` (turnover penalty)

This does not affect Pareto pruning—only “pick one” ranking.

------------------------------------------------------------------------

## 10) How to Add / Modify a Method Family

To add a new method:

1.  Implement `sampler()`, `editor(params)`, and
    `weight_fn_factory(params, constraints)` in `R/methods.R`.
2.  Add the family name to `default_method_families()`.
3.  Update `sanitize_params()` and the LLM grammar in `R/llm_planner.R`.

Guidelines: - Keep params small and interpretable. - Make `editor()` a
small change operator. - Keep `weight_fn_factory()` deterministic and
cheap.

------------------------------------------------------------------------

## 11) Debugging & Operational Notes

### Determinism

-   Selection and evaluation are deterministic given:
    -   fixed random seed (if you use sampling)
    -   fixed LLM response
-   For reproducibility:
    -   call `set.seed(...)` before `run_tot()`
    -   save LLM responses (future enhancement)

### Common failure modes

-   **NAs in objectives**: handled by feasibility checks; nodes become
    infeasible.
-   **Duplicate candidates**: prevented by `dedup_by_spec()`.
-   **LLM format issues**: fallback seeds guarantee progress.

### Running without LLM

Set `use_llm = FALSE` to test evaluation/selection deterministically.

------------------------------------------------------------------------

## 12) Entry Points

-   `run.R`: convenience driver (interactive or `Rscript`)
-   `R/load_all.R`: sources all modules in order
-   `run_tot()`: the main API for the project

------------------------------------------------------------------------

## 13) Quick “Change Recipes”

### Make the search cheaper

-   Reduce `n_rounds`
-   Reduce `edits_per_parent`
-   Reduce `K_per_method`
-   Reduce `medium` months in `oos_months_for_level()`

### Make the search more thorough

-   Increase `n_rounds`
-   Increase `edits_per_parent`
-   Increase `K_per_method`
-   Increase `medium` months
-   Add more method families

### Change constraints (example: max weight)

-   In `run_tot(constraints = list(max_w = 0.5))`
-   Ensure method weight projection respects it (already enforced in
    evaluation)

------------------------------------------------------------------------

## 14) Glossary

-   **Node**: one strategy specification and its evaluation.
-   **Frontier**: the current set of best candidates kept after pruning.
-   **Method family**: strategy construction category (diversity axis).
-   **FAST/MEDIUM/DEEP**: evaluation budgets based on how many OOS
    months are used.
-   **Pareto non-dominated**: not strictly worse across all objectives
    relative to another candidate.
